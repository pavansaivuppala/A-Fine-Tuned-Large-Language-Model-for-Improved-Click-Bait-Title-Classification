{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oiz9I30WFkik",
        "outputId": "2d9aee20-1937-49ad-be34-6ebd8b5500d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a pandas dataframe\n",
        "df = pd.read_csv(\"/content/dataset_file_name\")\n",
        "\n",
        "df[\"completion\"] = df[\"completion\"].replace({1: True, 0: False})\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "wppIosDoFspT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_json(\"Dataset_file_name_jsonformat.jsonl\", orient='records', lines=True)#converting dataframe to json file"
      ],
      "metadata": {
        "id": "3W8A_c_FF3Ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!openai tools fine_tunes.prepare_data -f Dataset_file_name_jsonformat.jsonl -q #preprocessing the data and to split the data into training and validation file"
      ],
      "metadata": {
        "id": "zObF3SMOF3OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finetuning the ada model with train and validation data files with parameter set to 4 epoch, where we can change it to n epochs.\n",
        "import openai\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"OPEN_API_KEY_VALUE\"\n",
        "!openai api fine_tunes.create -t \"new_prepared_train.jsonl\" -v \"new_prepared_valid.jsonl\" --compute_classification_metrics --classification_positive_class \" True\" -m ada  --n_epochs 4"
      ],
      "metadata": {
        "id": "jia-8-Q7F3AN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i 'fine-tune-ID' #you can view the fine-tuning process completion step by step."
      ],
      "metadata": {
        "id": "06lD3XMKGRru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.read_csv('new_train_result_file.csv')#results of training can be obtained an stored in new file\n",
        "results[results['classification/accuracy'].notnull()].tail(1)"
      ],
      "metadata": {
        "id": "L9Qxv0M6GXkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results[results['classification/accuracy'].notnull()]['classification/accuracy'].plot()# plotting the classification accuracy"
      ],
      "metadata": {
        "id": "59gkqbofGcDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to pass the prompt as the parameter and returns completion as the output\n",
        "def opai(m):\n",
        " openai.api_key = \"API_KEY_VALUE\"\n",
        " model_engine = 'MODEL_NAME'#enter the obtained model name in order to check the working of the model.\n",
        " prompt=m\n",
        " completions = openai.Completion.create(\n",
        "    engine=model_engine,\n",
        "    prompt=prompt,\n",
        "    max_tokens=1,\n",
        "    logprobs=2,\n",
        "    temperature=0\n",
        " )\n",
        "\n",
        " message = completions.choices[0].text\n",
        "\n",
        " return message"
      ],
      "metadata": {
        "id": "_Za6aFV8GprS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing of model with test dataset\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import openai\n",
        "from urllib import request\n",
        "df = pd.read_csv('/content/test_data_file.csv')#insert test dataset file here\n",
        "df.columns\n",
        "df['model_4_epch']=' '\n",
        "for index,rows in df.iterrows():\n",
        "  m=df['prompt'].values[index]\n",
        "  m= m+'->'\n",
        "  res=opai(m)\n",
        "  df['model_4_epch'].values[index]=res\n",
        "df.to_csv('test_results.csv')#converting dataframe to csv file which is test results stored in the file 'test_results.csv'."
      ],
      "metadata": {
        "id": "qSfAtk6zHGCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1YChGpME4Sr"
      },
      "outputs": [],
      "source": [
        "#plotting the confusion matrix for particular model\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "df = pd.read_csv('/content/test_results.csv')#give test results file name\n",
        "\n",
        "df[\"column_model_name\"] = df[\"column_model_name\"].apply(lambda x: True if x == \" True\" else False)#enter cloumn name of themodel result stored in test_results.csv file.\n",
        "labels = df['completion'].values\n",
        "predictions = df['column_model_name'].values\n",
        "\n",
        "# Get confusion matrix with labels in correct order\n",
        "cm = confusion_matrix(labels, predictions, labels=[True, False])\n",
        "cm = cm[[0, 1], :]\n",
        "cm = cm[:, [0, 1]]\n",
        "\n",
        "# Plot confusion matrix as heatmap\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=[\"True\", \"False\"], yticklabels=[\"True\", \"False\"])\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    }
  ]
}